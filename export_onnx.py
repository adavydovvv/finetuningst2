#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤ ONNX
"""

import os
import sys
import torch
import onnx
import timm
import argparse
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ experiments
ROOT = Path(".").resolve()
sys.path.append(str(ROOT / "experiments"))

from configs import BEST_MODEL_CONFIG

def export_model_to_onnx(model_name, num_classes=3, image_size=224, models_dir=None):
    """–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX"""
    
    if models_dir is None:
        models_dir = ROOT / "models"
    else:
        models_dir = Path(models_dir)
    
    print(f"üöÄ –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ {model_name} –≤ ONNX")
    print("="*50)
    
    print(f"–ú–æ–¥–µ–ª—å: {model_name}")
    print(f"–ö–ª–∞—Å—Å—ã: {num_classes}")
    print(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_size}")
    print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {models_dir}")
    
    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    weights_path = models_dir / f"best_{model_name}.pth"
    onnx_path = models_dir / f"{model_name}.onnx"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤–µ—Å–æ–≤
    if not weights_path.exists():
        print(f"‚ùå –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {weights_path}")
        print("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å:")
        print(f"python experiments/train.py --model_name {model_name} --epochs 12")
        return False
    
    try:
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_name}...")
        model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –∏–∑ {weights_path}...")
        model.load_state_dict(torch.load(weights_path, map_location='cpu'))
        model.eval()
        
        # –°–æ–∑–¥–∞–µ–º dummy input
        dummy_input = torch.randn(1, 3, image_size, image_size)
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
        print(f"üîÑ –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX...")
        torch.onnx.export(
            model,
            dummy_input,
            str(onnx_path),
            export_params=True,
            opset_version=18,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_shapes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º ONNX –º–æ–¥–µ–ª—å
        print(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏...")
        onnx_model = onnx.load(str(onnx_path))
        onnx.checker.check_model(onnx_model)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
        file_size = onnx_path.stat().st_size / 1024 / 1024
        print(f"\nüéâ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÅ –§–∞–π–ª: {onnx_path}")
        print(f"üìè –†–∞–∑–º–µ—Ä: {file_size:.2f} MB")
        
        # –¢–µ—Å—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        print(f"\nüß™ –¢–µ—Å—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...")
        import onnxruntime as ort
        session = ort.InferenceSession(str(onnx_path), providers=['CPUExecutionProvider'])
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        test_input = torch.randn(1, 3, image_size, image_size).numpy().astype('float32')
        outputs = session.run(None, {'input': test_input})
        
        print(f"‚úÖ –¢–µ—Å—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: {outputs[0].shape}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX')
    parser.add_argument('--model_name', type=str, default=BEST_MODEL_CONFIG.model_name,
                       help=f'–ò–º—è –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {BEST_MODEL_CONFIG.model_name})')
    parser.add_argument('--num_classes', type=int, default=3,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3)')
    parser.add_argument('--image_size', type=int, default=BEST_MODEL_CONFIG.image_size,
                       help=f'–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {BEST_MODEL_CONFIG.image_size})')
    parser.add_argument('--models_dir', type=str, default='models',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: models)')
    
    args = parser.parse_args()
    
    success = export_model_to_onnx(
        model_name=args.model_name,
        num_classes=args.num_classes,
        image_size=args.image_size,
        models_dir=args.models_dir
    )
    
    if success:
        print(f"\nüöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
        print(f"python app/gradio_app.py")
    else:
        print(f"\n‚ùå –≠–∫—Å–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—à–∏–±–∫–∏ –≤—ã—à–µ.")

if __name__ == "__main__":
    main()
